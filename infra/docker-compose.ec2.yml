version: '3.8'

# Optimized docker-compose for single EC2 instance deployment
# This configuration is memory-optimized for t3.micro/t3.small instances

services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: epl-zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      # Memory optimization
      KAFKA_HEAP_OPTS: "-Xmx256M -Xms256M"
    volumes:
      - zookeeper-data:/var/lib/zookeeper/data
      - zookeeper-logs:/var/lib/zookeeper/log
    restart: unless-stopped
    networks:
      - epl-network
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "2181"]
      interval: 30s
      timeout: 5s
      retries: 3

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: epl-kafka
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_LOG_RETENTION_HOURS: 168
      KAFKA_LOG_SEGMENT_BYTES: 1073741824
      KAFKA_NUM_PARTITIONS: 3
      # Memory optimization for small instances
      KAFKA_HEAP_OPTS: "-Xmx512M -Xms512M"
      KAFKA_JVM_PERFORMANCE_OPTS: "-XX:MetaspaceSize=96m -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35"
    volumes:
      - kafka-data:/var/lib/kafka/data
    restart: unless-stopped
    networks:
      - epl-network
    healthcheck:
      test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server", "localhost:9092"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  redis:
    image: redis:7-alpine
    container_name: epl-redis
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    # Memory limit and optimization
    command: redis-server --appendonly yes --maxmemory 256mb --maxmemory-policy allkeys-lru
    restart: unless-stopped
    networks:
      - epl-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5

  producer:
    build:
      context: ../services/producer
      dockerfile: Dockerfile
    container_name: epl-producer
    depends_on:
      kafka:
        condition: service_healthy
      redis:
        condition: service_healthy
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
      - KAFKA_TOPIC=epl.matches
      - REDIS_URL=redis://redis:6379
      - FOOTBALL_API_KEY=${FOOTBALL_API_KEY}
      - ENABLE_MOCK_DATA=${ENABLE_MOCK_DATA:-false}
    restart: unless-stopped
    networks:
      - epl-network
    # Memory limit for small instances
    mem_limit: 256m
    mem_reservation: 128m

  consumer:
    build:
      context: ../services/consumer
      dockerfile: Dockerfile
    container_name: epl-consumer
    depends_on:
      kafka:
        condition: service_healthy
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
      - KAFKA_TOPIC=epl.matches
      - KAFKA_GROUP_ID=epl-consumer-group
      - CONVEX_URL=${CONVEX_URL}
      - CONVEX_DEPLOY_KEY=${CONVEX_DEPLOY_KEY:-}
    restart: unless-stopped
    networks:
      - epl-network
    # Memory limit for small instances
    mem_limit: 256m
    mem_reservation: 128m

  # Optional: Kafka UI for debugging (disable on t3.micro to save memory)
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: epl-kafka-ui
    depends_on:
      kafka:
        condition: service_healthy
    environment:
      KAFKA_CLUSTERS_0_NAME: epl-cluster
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9092
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181
    ports:
      - "8080:8080"
    networks:
      - epl-network
    restart: unless-stopped
    # Only start if you have enough memory (comment out for t3.micro)
    profiles:
      - debug

volumes:
  zookeeper-data:
  zookeeper-logs:
  kafka-data:
  redis-data:

networks:
  epl-network:
    driver: bridge
